{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YsU_xnT-NZCFYlsULbBpigTyhyXc6Xjh",
      "authorship_tag": "ABX9TyPU9UjzoqaUMfQG6Ge0BKWF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phyllisnabangi/sunbirdai/blob/main/SpeechDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing dependencies"
      ],
      "metadata": {
        "id": "qB9TY2l_BwQX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBfM1Bi4A2Z9",
        "outputId": "b51f8620-7efc-458e-bfe3-1046049cd819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 huggingface-hub-0.16.4 multiprocess-0.70.15 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install pydub\n",
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "88qQVnDGCCIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "import audioread\n"
      ],
      "metadata": {
        "id": "-7sorFdqByKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data in the speech-data folder"
      ],
      "metadata": {
        "id": "AO4pLG3jCJFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l \"/content/drive/Shareddrives/Sunbird AI/Internships/internship-experiments/speech-data\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_klwKSmNkv7",
        "outputId": "d0c46e5d-d30f-4f7c-9846-105a4edbdffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1141572\n",
            "dr-x------ 2 root root       4096 Aug 24 12:32 Ateso\n",
            "-r-------- 1 root root 1163387946 Aug 24 12:24 backup_uganda_raw_dataset.zip\n",
            "-r-------- 1 root root    5568626 Aug 29 13:38 drive-download-20230829T133716Z-001.zip\n",
            "dr-x------ 2 root root       4096 Aug 24 12:32 Luganda\n",
            "dr-x------ 2 root root       4096 Aug 28 08:57 Runyankole\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r \"/content/drive/Shareddrives/Sunbird AI/Projects/African Language Technology/Data/Runyankole Voice Over/Runyankole\" \"/content/drive/Shareddrives/Sunbird AI/Internships/internship-experiments/speech-data/\"\n",
        "\n",
        "# No write permissions - uploaded the files manually"
      ],
      "metadata": {
        "id": "tpq560bjCHyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/Shareddrives/Sunbird AI/Internships/internship-experiments/speech-data/backup_uganda_raw_dataset.zip'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YAQTrESeNo3",
        "outputId": "d944e4a9-a62b-4e84-f155-6a6c1e359e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/Shareddrives/Sunbird AI/Internships/internship-experiments/speech-data/backup_uganda_raw_dataset.zip\n",
            " extracting: backup_uganda_raw_dataset/audio_24.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_20.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_29.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_23.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_27.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_13.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_37.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_8.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_22.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_10.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_36.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_7.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_26.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_30.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_15.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_6.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_5.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_25.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_12.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_17.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_40.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_38.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_39.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_1.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_2.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_4.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_18.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_3.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_28.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_16.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_9.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_11.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_34.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_33.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_21.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_31.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_35.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_19.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_41.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_14.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_32.mp3  \n",
            " extracting: backup_uganda_raw_dataset/audio_transcript_mapping.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to wav\n",
        "def convert_to_wav(input_folder, output_folder):\n",
        "    try:\n",
        "        # Ensure the output folder exists\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "        # Iterate over all files in the input folder\n",
        "        for filename in os.listdir(input_folder):\n",
        "            if filename.lower().endswith((\".mp3\", \".ogg\", \".flac\")):\n",
        "                # Build paths for input and output files\n",
        "                input_file = os.path.join(input_folder, filename)\n",
        "                output_file = os.path.join(output_folder, os.path.splitext(filename)[0] + \".wav\")\n",
        "\n",
        "                # Load the input audio file using pydub\n",
        "                audio = AudioSegment.from_file(input_file)\n",
        "\n",
        "                # Export the audio to WAV format\n",
        "                audio.export(output_file, format=\"wav\")\n",
        "\n",
        "        return True  # Conversion successful for all files\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return False  # Conversion failed\n"
      ],
      "metadata": {
        "id": "3TGVOWUjj6aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the Acholi dataset from mp3 to wav\n",
        "input_folder = \"backup_uganda_raw_dataset\"\n",
        "output_folder = \"Acholi_wav\"\n",
        "\n",
        "conversion_result = convert_to_wav(input_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "skoNk-hanBog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting audios into chuncks\n",
        "def chunk_audio(audio, chunk_size_ms, overlap_ms):\n",
        "  # chunk_size -> numnber of milliseconds for each chunk\n",
        "  # overlap_ms -> overlap between each chunk so we do not lose some data\n",
        "    sound = AudioSegment.from_wav(audio)\n",
        "    duration = len(sound)\n",
        "\n",
        "    chunks = []\n",
        "    start_time = 0\n",
        "\n",
        "    while start_time + chunk_size_ms <= duration:\n",
        "        end_time = start_time + chunk_size_ms\n",
        "        chunk = sound[start_time:end_time]\n",
        "        chunks.append(chunk)\n",
        "        start_time += chunk_size_ms - overlap_ms\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "0jUb9omYoR6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_dir = \"/content/drive/Shareddrives/Sunbird AI/Internships/internship-experiments/speech-data/Runyankole\"\n",
        "input_dir = \"Acholi_wav\"\n",
        "output_dir = \"/content/chunked_audio/\""
      ],
      "metadata": {
        "id": "t0vp3GhEoSW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "audio_files = glob.glob(os.path.join(input_dir, \"*.wav\"))\n",
        "\n",
        "for audio in audio_files:\n",
        "    audio_name = os.path.splitext(os.path.basename(audio))[0]\n",
        "    audio_dir = os.path.join(output_dir, audio_name)\n",
        "\n",
        "    if not os.path.exists(audio_dir):\n",
        "        os.makedirs(audio_dir)\n",
        "\n",
        "    chunks = chunk_audio(audio, chunk_size_ms=30000, overlap_ms=1000)\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_path = os.path.join(audio_dir, f\"c{i+1}.wav\")\n",
        "        chunk.export(chunk_path, format=\"wav\")"
      ],
      "metadata": {
        "id": "1DopOWDtJfbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/Shareddrives/Sunbird AI/Internships/internship-experiments/speech-data/Runyankole\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anGy63CWqU6B",
        "outputId": "5bea4e6c-4416-4661-c365-b9af8d3ff288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'RUNYANKOLE 0.wav'\t'RUNYANKOLE 30.wav'\t'RUNYANKOLE 64.wav'\n",
            "'RUNYANKOLE 10(1).wav'\t'RUNYANKOLE 31(1).wav'\t'RUNYANKOLE 65.wav'\n",
            "'RUNYANKOLE 10.wav'\t'RUNYANKOLE 31.wav'\t'RUNYANKOLE 66.wav'\n",
            "'RUNYANKOLE 11(1).wav'\t'RUNYANKOLE 32.wav'\t'RUNYANKOLE 67.wav'\n",
            "'RUNYANKOLE 11.wav'\t'RUNYANKOLE 33.wav'\t'RUNYANKOLE 68.wav'\n",
            "'RUNYANKOLE 12(1).wav'\t'RUNYANKOLE 34.wav'\t'RUNYANKOLE 69.wav'\n",
            "'RUNYANKOLE 12.wav'\t'RUNYANKOLE 35(1).wav'\t'RUNYANKOLE 6.wav'\n",
            "'RUNYANKOLE 13(1).wav'\t'RUNYANKOLE 35.wav'\t'RUNYANKOLE 70.wav'\n",
            "'RUNYANKOLE 13.wav'\t'RUNYANKOLE 36(1).wav'\t'RUNYANKOLE 71.wav'\n",
            "'RUNYANKOLE 14(1).wav'\t'RUNYANKOLE 36.wav'\t'RUNYANKOLE 72.wav'\n",
            "'RUNYANKOLE 14.wav'\t'RUNYANKOLE 37(1).wav'\t'RUNYANKOLE 73.wav'\n",
            "'RUNYANKOLE 15.wav'\t'RUNYANKOLE 37.wav'\t'RUNYANKOLE 74.wav'\n",
            "'RUNYANKOLE 16.wav'\t'RUNYANKOLE 38(1).wav'\t'RUNYANKOLE 75.wav'\n",
            "'RUNYANKOLE 17.wav'\t'RUNYANKOLE 38.wav'\t'RUNYANKOLE 76.wav'\n",
            "'RUNYANKOLE 18.wav'\t'RUNYANKOLE 39.wav'\t'RUNYANKOLE 77.wav'\n",
            "'RUNYANKOLE 19.wav'\t'RUNYANKOLE 3.wav'\t'RUNYANKOLE 78.wav'\n",
            "'RUNYANKOLE 1.wav'\t'RUNYANKOLE 40.wav'\t'RUNYANKOLE 79.wav'\n",
            "'RUNYANKOLE 20(1).wav'\t'RUNYANKOLE 41.wav'\t'RUNYANKOLE 7.wav'\n",
            "'RUNYANKOLE 20.wav'\t'RUNYANKOLE 42.wav'\t'RUNYANKOLE 80.wav'\n",
            "'RUNYANKOLE 21(1).wav'\t'RUNYANKOLE 43.wav'\t'RUNYANKOLE 81.wav'\n",
            "'RUNYANKOLE 21(2).wav'\t'RUNYANKOLE 44.wav'\t'RUNYANKOLE 82.wav'\n",
            "'RUNYANKOLE 21(3).wav'\t'RUNYANKOLE 45.wav'\t'RUNYANKOLE 83.wav'\n",
            "'RUNYANKOLE 21.wav'\t'RUNYANKOLE 46.wav'\t'RUNYANKOLE 84.wav'\n",
            "'RUNYANKOLE 22(1).wav'\t'RUNYANKOLE 47.wav'\t'RUNYANKOLE 85.wav'\n",
            "'RUNYANKOLE 22.wav'\t'RUNYANKOLE 48.wav'\t'RUNYANKOLE 86.wav'\n",
            "'RUNYANKOLE 23(1).wav'\t'RUNYANKOLE 49.wav'\t'RUNYANKOLE 87.wav'\n",
            "'RUNYANKOLE 23(2).wav'\t'RUNYANKOLE 4.wav'\t'RUNYANKOLE 88.wav'\n",
            "'RUNYANKOLE 23.wav'\t'RUNYANKOLE 50.wav'\t'RUNYANKOLE 89.wav'\n",
            "'RUNYANKOLE 24(1).wav'\t'RUNYANKOLE 51.wav'\t'RUNYANKOLE 8.wav'\n",
            "'RUNYANKOLE 24.wav'\t'RUNYANKOLE 52.wav'\t'RUNYANKOLE 90.wav'\n",
            "'RUNYANKOLE 25(1).wav'\t'RUNYANKOLE 53.wav'\t'RUNYANKOLE 91.wav'\n",
            "'RUNYANKOLE 25(2).wav'\t'RUNYANKOLE 54.wav'\t'RUNYANKOLE 92.wav'\n",
            "'RUNYANKOLE 25.wav'\t'RUNYANKOLE 55.wav'\t'RUNYANKOLE 93.wav'\n",
            "'RUNYANKOLE 26(1).wav'\t'RUNYANKOLE 56.wav'\t'RUNYANKOLE 94.wav'\n",
            "'RUNYANKOLE 26.wav'\t'RUNYANKOLE 57.wav'\t'RUNYANKOLE 95.wav'\n",
            "'RUNYANKOLE 27(1).wav'\t'RUNYANKOLE 58.wav'\t'RUNYANKOLE 96.wav'\n",
            "'RUNYANKOLE 27.wav'\t'RUNYANKOLE 59.wav'\t'RUNYANKOLE 97.wav'\n",
            "'RUNYANKOLE 28(1).wav'\t'RUNYANKOLE 5.wav'\t'RUNYANKOLE 98.wav'\n",
            "'RUNYANKOLE 28.wav'\t'RUNYANKOLE 60.wav'\t'RUNYANKOLE 99.wav'\n",
            "'RUNYANKOLE 29(1).wav'\t'RUNYANKOLE 61.wav'\t'RUNYANKOLE 9.wav'\n",
            "'RUNYANKOLE 29.wav'\t'RUNYANKOLE 62.wav'\n",
            "'RUNYANKOLE 2.wav'\t'RUNYANKOLE 63.wav'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/chunked_audio/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PioA9f5qmYV",
        "outputId": "88a0a393-5624-4f07-97c7-657d29a6232d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio_1   audio_15  audio_20  audio_26\taudio_31  audio_37  audio_5\n",
            "audio_10  audio_16  audio_21  audio_27\taudio_32  audio_38  audio_6\n",
            "audio_11  audio_17  audio_22  audio_28\taudio_33  audio_39  audio_7\n",
            "audio_12  audio_18  audio_23  audio_29\taudio_34  audio_4   audio_8\n",
            "audio_13  audio_19  audio_24  audio_3\taudio_35  audio_40  audio_9\n",
            "audio_14  audio_2   audio_25  audio_30\taudio_36  audio_41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chuncking on silence detection\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "\n",
        "def chunk_audio_on_silence(audio, silence_threshold=-30):\n",
        "    sound = AudioSegment.from_wav(audio)\n",
        "\n",
        "    # Split audio based on silence detection\n",
        "    audio_chunks = split_on_silence(\n",
        "        sound,\n",
        "        # min_silence_duration=min_silence_len,\n",
        "        silence_thresh=silence_threshold,\n",
        "        keep_silence=True\n",
        "    )\n",
        "\n",
        "    return audio_chunks\n"
      ],
      "metadata": {
        "id": "P03BgAdhrauL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input directory containing audio files\n",
        "input_dir = \"Acholi_wav\"\n",
        "output_dir = \"/content/chunked_audio/Acholi\" # the output directory for the chunked audio\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# List all audio files in the input directory\n",
        "audio_files = glob.glob(os.path.join(input_dir, \"*.wav\"))\n",
        "\n",
        "# Process each audio file and export the chunks\n",
        "for audio_file in audio_files:\n",
        "    # Create a directory for each audio file's chunks within the output directory\n",
        "    audio_name = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "    audio_dir = os.path.join(output_dir, audio_name)\n",
        "\n",
        "    if not os.path.exists(audio_dir):\n",
        "        os.makedirs(audio_dir)\n",
        "\n",
        "    # Chunk the audio based on silence detection\n",
        "    audio_chunks = chunk_audio_on_silence(audio_file)\n",
        "\n",
        "    # Export or process audio chunks as needed\n",
        "    for i, chunk in enumerate(audio_chunks):\n",
        "        chunk_path = os.path.join(audio_dir, f\"c{i+1}.wav\")\n",
        "        chunk.export(chunk_path, format=\"wav\")\n"
      ],
      "metadata": {
        "id": "vHQm_Hi7Yl4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking pydub version\n",
        "!pip show pydub"
      ],
      "metadata": {
        "id": "u1mYP8CM5d-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "VK9rsW6qZGJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Needed imports\n",
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile"
      ],
      "metadata": {
        "id": "p2tt4S31XGlI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already read the audio file using librosa\n",
        "audio_data, sample_rate = librosa.load('/content/chunked_audio/Acholi/audio_1')\n",
        "\n",
        "# Play the audio\n",
        "Audio(data=audio_data, rate=sample_rate)\n"
      ],
      "metadata": {
        "id": "S0lvzdipb9AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a player for mono sound\n",
        "Audio(data,rate=framerate)"
      ],
      "metadata": {
        "id": "gHG92ohwXt-6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}